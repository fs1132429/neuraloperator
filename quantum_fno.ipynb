{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: qutip in /home/freya/.local/lib/python3.10/site-packages (5.0.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /usr/lib/python3/dist-packages (from qutip) (1.8.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from qutip) (21.3)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/freya/.local/lib/python3.10/site-packages (from qutip) (1.26.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in /home/freya/.local/lib/python3.10/site-packages (0.16.6)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/lib/python3/dist-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/lib/python3/dist-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/lib/python3/dist-packages (from wandb) (4.21.12)\n",
      "Requirement already satisfied: setproctitle in /home/freya/.local/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/lib/python3/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/freya/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/freya/.local/lib/python3.10/site-packages (from wandb) (1.44.1)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/freya/.local/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/freya/.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: urllib3>=1.26.11 in /home/freya/.local/lib/python3.10/site-packages (from sentry-sdk>=1.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb) (2020.6.20)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/freya/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch_harmonics in /home/freya/.local/lib/python3.10/site-packages (0.6.5)\n",
      "Requirement already satisfied: torch in /usr/lib/python3/dist-packages (from torch_harmonics) (2.0.1)\n",
      "Requirement already satisfied: numpy in /home/freya/.local/lib/python3.10/site-packages (from torch_harmonics) (1.26.4)\n",
      "Requirement already satisfied: triton in /usr/lib/python3/dist-packages (from torch_harmonics) (2.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorly in /home/freya/.local/lib/python3.10/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy in /home/freya/.local/lib/python3.10/site-packages (from tensorly) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from tensorly) (1.8.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorly-torch in /home/freya/.local/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: nose in /usr/lib/python3/dist-packages (from tensorly-torch) (1.3.7)\n",
      "Requirement already satisfied: numpy in /home/freya/.local/lib/python3.10/site-packages (from tensorly-torch) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from tensorly-torch) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install qutip\n",
    "!pip install wandb\n",
    "!pip install torch_harmonics\n",
    "!pip install tensorly \n",
    "!pip install -U tensorly-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "#import stuff from library\n",
    "from neuralop.models import FNO1d\n",
    "from neuralop import Trainer\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from neuralop.datasets.data_transforms import DefaultDataProcessor\n",
    "from neuralop.datasets.tensor_dataset import TensorDataset\n",
    "from neuralop.datasets.output_encoder import UnitGaussianNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_input_states_wavefunction(N, num_states):\n",
    "    input_states = torch.zeros((num_states, 2**N), dtype=torch.complex64)\n",
    "    for i in range(num_states):\n",
    "        # Generate random complex amplitudes for each spin state\n",
    "        real_part = torch.rand(2**N) * 2 - 1  # Random real part between -1 and 1\n",
    "        imag_part = torch.rand(2**N) * 2 - 1  # Random imag part between -1 and 1\n",
    "        amplitudes = real_part + 1j * imag_part\n",
    "        norm = torch.linalg.norm(amplitudes)  \n",
    "        amplitudes /= norm  # Normalize the wavefunction\n",
    "        input_states[i] = amplitudes\n",
    "    return input_states\n",
    "\n",
    "def evolve_states(input_states, hamiltonian, times):\n",
    "    num_states, _ = input_states.shape\n",
    "    output_states = torch.zeros_like(input_states, dtype=torch.complex64)\n",
    "    for i in range(num_states):\n",
    "        state = input_states[i]\n",
    "        output_state = torch.zeros_like(state, dtype=torch.complex64)\n",
    "        for t in times:\n",
    "            evolution_operator = torch.exp(-1j * hamiltonian * t)\n",
    "            evolved_state = torch.matmul(evolution_operator, state)\n",
    "            output_state = evolved_state / torch.linalg.norm(evolved_state)\n",
    "        output_states[i] = output_state\n",
    "    return output_states\n",
    "\n",
    "\n",
    "def construct_hamiltonian(n_particles, J=1):\n",
    "    # Define spin operators for a single particle\n",
    "    sx = (1/2) * torch.tensor([[0, 1], [1, 0]])\n",
    "    sy = (1/2) * torch.tensor([[0, -1j], [1j, 0]])\n",
    "    sz = (1/2) * torch.tensor([[1, 0], [0, -1]])\n",
    "\n",
    "    hamiltonian = torch.zeros((2**n_particles, 2**n_particles), dtype=torch.complex64)\n",
    "    # Create identity matrix for n_particles\n",
    "    identity = torch.eye(2**(n_particles-1))\n",
    "\n",
    "    # Extend single-particle operators to n_particles\n",
    "    sx_total = torch.kron(sx, identity) + torch.kron(identity, sx)\n",
    "    sy_total = torch.kron(sy, identity) + torch.kron(identity, sy)\n",
    "    sz_total = torch.kron(sz, identity) + torch.kron(identity, sz)\n",
    "    \n",
    "    # Nearest particle interaction\n",
    "    for i in range(n_particles-1):\n",
    "        szsz = torch.matmul(sz_total, sz_total)\n",
    "        sxsx = torch.matmul(sx_total, sx_total)\n",
    "        sysy = torch.matmul(sy_total, sy_total)\n",
    "        # Hamiltonian\n",
    "        hamiltonian += J * (szsz + sxsx + sysy)\n",
    "\n",
    "    return hamiltonian\n",
    "\n",
    "\n",
    "def plot_state_vectors(input_states):\n",
    "    N = int(np.log2(len(input_states[0])))  # Number of qubits\n",
    "    for i, state in enumerate(input_states):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 4))  # Create two subplots side by side\n",
    "        axs[0].bar(range(2**N), np.abs(state)**2, label='Real', color='b', alpha=0.7)\n",
    "        axs[0].set_title(f\"State {i+1} - Real Part\")\n",
    "        axs[0].set_xlabel(\"Basis State\")\n",
    "        axs[0].set_ylabel(\"Probability\")\n",
    "        axs[0].legend()\n",
    "\n",
    "        axs[1].bar(range(2**N), np.imag(state)**2, label='Imaginary', color='r', alpha=0.7)\n",
    "        axs[1].set_title(f\"State {i+1} - Imaginary Part\")\n",
    "        axs[1].set_xlabel(\"Basis State\")\n",
    "        axs[1].set_ylabel(\"Probability\")\n",
    "        axs[1].legend()\n",
    "\n",
    "        plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def create_dataset(N, num_states, train_ratio, batch_size):\\n    # Generate input states\\n    input_states_wavefunction = generate_random_input_states_wavefunction(N, num_states)\\n\\n    # Define evolution times\\n    times = torch.linspace(0, 1, 100)\\n\\n    # Construct Hamiltonian\\n    hamiltonian = construct_hamiltonian(N)\\n\\n    # Evolve input states\\n    output_states = evolve_states(input_states_wavefunction, hamiltonian, times)\\n    \\n    # Generate spatial grid\\n    spatial_grid = torch.linspace(0, 1, 2**N).unsqueeze(0).expand(num_states, -1)\\n\\n    # Concatenate spatial grid with input states\\n    train_input = torch.cat([input_states_wavefunction.unsqueeze(-1), spatial_grid.unsqueeze(-1)], dim=-1)\\n\\n    # Split data into training and testing sets\\n    train_size = int(train_ratio * num_states)\\n\\n    train_input_final, train_output_final = train_input[:train_size], output_states[:train_size]\\n    test_input, test_output = train_input[train_size:], output_states[train_size:]\\n\\n    print(f'[Dataset] x_train: {train_input_final.shape}, y_train: {train_output_final.shape}')\\n    print(f'[Dataset] x_test: {test_input.shape}, y_test: {test_output.shape}')\\n\\n    # Create data loaders\\n    train_loader = torch.utils.data.DataLoader(\\n        torch.utils.data.TensorDataset(train_input_final, train_output_final),\\n        batch_size=batch_size,\\n        shuffle=True\\n    )\\n    test_loader = torch.utils.data.DataLoader(\\n        torch.utils.data.TensorDataset(test_input, test_output),\\n        batch_size=batch_size,\\n        shuffle=False\\n    )\\n    return train_loader, test_loader\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"def create_dataset(N, num_states, train_ratio, batch_size):\n",
    "    # Generate input states\n",
    "    input_states_wavefunction = generate_random_input_states_wavefunction(N, num_states)\n",
    "\n",
    "    # Define evolution times\n",
    "    times = torch.linspace(0, 1, 100)\n",
    "\n",
    "    # Construct Hamiltonian\n",
    "    hamiltonian = construct_hamiltonian(N)\n",
    "\n",
    "    # Evolve input states\n",
    "    output_states = evolve_states(input_states_wavefunction, hamiltonian, times)\n",
    "    \n",
    "    # Generate spatial grid\n",
    "    spatial_grid = torch.linspace(0, 1, 2**N).unsqueeze(0).expand(num_states, -1)\n",
    "\n",
    "    # Concatenate spatial grid with input states\n",
    "    train_input = torch.cat([input_states_wavefunction.unsqueeze(-1), spatial_grid.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(train_ratio * num_states)\n",
    "\n",
    "    train_input_final, train_output_final = train_input[:train_size], output_states[:train_size]\n",
    "    test_input, test_output = train_input[train_size:], output_states[train_size:]\n",
    "\n",
    "    print(f'[Dataset] x_train: {train_input_final.shape}, y_train: {train_output_final.shape}')\n",
    "    print(f'[Dataset] x_test: {test_input.shape}, y_test: {test_output.shape}')\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(train_input_final, train_output_final),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(test_input, test_output),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(spatial_dims, grid_boundary, dtype):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        spatial_dims : torch.size\n",
    "            Sizes of spatial resolution.\n",
    "        device : str\n",
    "            Device where to load data ('cpu' or 'cuda:*').\n",
    "        dtype : str\n",
    "            Data type to encode data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Output grids to concatenate.\n",
    "        \"\"\"\n",
    "        grid_x = torch.linspace(grid_boundary[0], grid_boundary[1], spatial_dims,dtype=dtype).unsqueeze(-1)\n",
    "        return grid_x\n",
    "\n",
    "\n",
    "def positional_embedding_1d(data, grid_boundaries=[0, 1], batched=False):\n",
    "    \"\"\"Apply positional embedding as a regular 1D grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : torch.tensor\n",
    "        Input data to concatenate with positional embeddings.\n",
    "    grid_boundaries : list, optional\n",
    "        Coordinate boundaries of input grid, by default [0, 1].\n",
    "    batched : bool, optional\n",
    "        Whether the input data is batched, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor\n",
    "        Output tensor with positional embeddings concatenated.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if not batched:\n",
    "        if data.ndim == 2:\n",
    "            data = data.unsqueeze(-1)\n",
    "    batch_size = data.shape[0]\n",
    "    print(batch_size)\n",
    "    print(data.shape)\n",
    "    x = grid(data.shape[1],grid_boundaries, data.dtype)\n",
    "    print(x.shape)\n",
    "    out = torch.cat((data, x.expand(batch_size, -1, -1)),\n",
    "                    dim=-1)\n",
    "    print(out.shape)\n",
    "    # in the unbatched case, the dataloader will stack N\n",
    "    # examples with no batch dim to create one\n",
    "    if not batched and batch_size == 1:\n",
    "        return out.squeeze(0)\n",
    "    else:\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_format(x_train:torch.tensor,y_train:torch.tensor,x_test:torch.tensor,y_test:torch.tensor,\n",
    "                encoding:str = \"channel-wise\",\n",
    "                encode_input:bool = False ,encode_output:bool = False,\n",
    "                grid_boundaries:list = [0,1],\n",
    "                batch_size:int = 4,\n",
    "                positional_encoding:bool = True\n",
    "                ):\n",
    "\n",
    "    if encode_input:\n",
    "        if encoding == \"channel-wise\":\n",
    "            reduce_dims = list(range(x_train.ndim))\n",
    "        elif encoding == \"pixel-wise\":\n",
    "            reduce_dims = [0]\n",
    "\n",
    "        input_encoder = UnitGaussianNormalizer(dim=reduce_dims)\n",
    "        input_encoder.fit(x_train)\n",
    "        #x_train = input_encoder.transform(x_train)\n",
    "        #x_test = input_encoder.transform(x_test.contiguous())\n",
    "    else:\n",
    "        input_encoder = None\n",
    "\n",
    "    if encode_output:\n",
    "        if encoding == \"channel-wise\":\n",
    "            reduce_dims = list(range(y_train.ndim))\n",
    "        elif encoding == \"pixel-wise\":\n",
    "            reduce_dims = [0]\n",
    "\n",
    "        output_encoder = UnitGaussianNormalizer(dim=reduce_dims)\n",
    "        output_encoder.fit(y_train)\n",
    "        #y_train = output_encoder.transform(y_train)\n",
    "    else:\n",
    "        output_encoder = None\n",
    "\n",
    "    train_db = TensorDataset(\n",
    "        x_train,\n",
    "        y_train,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_db,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    test_db = TensorDataset(\n",
    "        x_test,\n",
    "        y_test,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_db,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    if positional_encoding:\n",
    "        pos_encoding = positional_embedding_1d(x_train,grid_boundaries)\n",
    "        #pos_encoding = grid(x_train.shape[1],grid_boundaries, x_train.dtype)\n",
    "    else:\n",
    "        pos_encoding = None\n",
    "    #data_processor = DefaultDataProcessor(\n",
    "        #in_normalizer=input_encoder,\n",
    "        #out_normalizer=output_encoder,\n",
    "       # positional_encoding=pos_encoding\n",
    "    #)\n",
    "    return train_loader, test_loader #, data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(N,num_states,train_ratio,batch_size):\n",
    "    # Generate input states\n",
    "    input_states_wavefunction = generate_random_input_states_wavefunction(N, num_states)\n",
    "\n",
    "    # Define evolution times\n",
    "    times = np.linspace(0, 1, 100)\n",
    "\n",
    "    # Construct Hamiltonian\n",
    "    hamiltonian = construct_hamiltonian(N)\n",
    "\n",
    "    # Evolve input states\n",
    "    output_states = evolve_states(input_states_wavefunction, hamiltonian, times)\n",
    "\n",
    "    input_states_wavefunction=np.array(input_states_wavefunction)\n",
    "    output_states=np.array(output_states)\n",
    "    # Convert to PyTorch tensors\n",
    "    input_states_tensor = torch.tensor(input_states_wavefunction, dtype=torch.complex64)\n",
    "    output_states_tensor = torch.tensor(output_states, dtype=torch.complex64)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(train_ratio * num_states)\n",
    "    train_input = input_states_tensor[:train_size]\n",
    "    train_output = output_states_tensor[:train_size]\n",
    "    test_input = input_states_tensor[train_size:]\n",
    "    test_output = output_states_tensor[train_size:]\n",
    "    \n",
    "    return train_input,train_output,test_input,test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "N = 4  # Number of particles\n",
    "num_states = 2000  # Number of input states\n",
    "train_ratio = 0.8  # Ratio of training to testing data\n",
    "batch_size=32\n",
    "modes= (2**N)//2 #+1\n",
    "hidden_channels=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "torch.Size([1600, 16, 1])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([1600, 16, 2])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa8b376a0e0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fa8b3647580>\n"
     ]
    }
   ],
   "source": [
    "train_input,train_output,test_input,test_output=create_dataset(N,num_states,train_ratio,batch_size)\n",
    "train_loader,test_loader= data_format(train_input,train_output,test_input,test_output, grid_boundaries = [0,2**N],batch_size=batch_size,\n",
    "                positional_encoding = True)\n",
    "print(train_loader)\n",
    "print(test_loader)\n",
    "#train_loader={'train_loader':train_loader}\n",
    "#test_loader={'test_loader':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNO1d(n_modes_height=modes,\n",
    "        hidden_channels=hidden_channels,\n",
    "        in_channels=2,\n",
    "        out_channels=1,\n",
    "        spatial_domain= 'complex')\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our model has 214593 parameters.\n"
     ]
    }
   ],
   "source": [
    "n_params = count_model_params(model)\n",
    "print(f'\\nOur model has {n_params} parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=8e-3,\n",
    "                                weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.override_load_to_device=False\n",
      "self.overrides_loss=False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (CUDAComplexFloatType) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1007878/2008852855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                           verbose=True)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m trainer.train(train_loader=train_loader,\n\u001b[0m\u001b[1;32m     14\u001b[0m                       \u001b[0mtest_loaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuraloperator/neuralop/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, test_loaders, optimizer, scheduler, regularizer, training_loss, eval_losses)\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuraloperator/neuralop/models/fno.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, output_shape, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain_padding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuraloperator/neuralop/layers/mlp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_linearity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (CUDAComplexFloatType) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "batch_size=32\n",
    "device='cuda'\n",
    "\n",
    "trainer = Trainer(model=model, n_epochs=epochs,\n",
    "    device=device,\n",
    "    data_processor=None,\n",
    "    wandb_log=False,\n",
    "    log_test_interval=1, # log at every epoch\n",
    "    use_distributed=False,\n",
    "    verbose=True)\n",
    "\n",
    "trainer.train(train_loader=train_loader,\n",
    "    test_loaders=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    regularizer=False,\n",
    "    training_loss=train_loss,\n",
    "    eval_losses=eval_losses,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
